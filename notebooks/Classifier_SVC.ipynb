{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.12 (default, Nov 19 2016, 06:48:10) \\n[GCC 5.4.0 20160609]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import collections\n",
    "import random \n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions\n",
    "def number_of_chars(s):\n",
    "    return len(s)\n",
    "\n",
    "def unique_chars(s):\n",
    "    s2 = ''.join(set(s))\n",
    "    return len(s2)\n",
    "\n",
    "def weighted_unique_chars(s):\n",
    "    return unique_chars(s)/number_of_chars(s)\n",
    "\n",
    "def words_count(s):\n",
    "    return collections.Counter(s)\n",
    "\n",
    "def words_counter_object(s):\n",
    "    cnt = collections.Counter()\n",
    "\n",
    "    words = s.split()\t\n",
    "    for w in words:\n",
    "        cnt[w] += 1\n",
    "\n",
    "    return cnt\n",
    "\n",
    "def total_words(cnt):\n",
    "    sum = 0\n",
    "    for k in dict(cnt).keys():\n",
    "        sum += int(cnt[k])\n",
    "\n",
    "    return sum\n",
    "\n",
    "def most_common(cnt, n):\n",
    "    for k,v in cnt.most_common(n):\n",
    "        #print \"most common  k = %s : v = %s\" %(k,v)\n",
    "        pass\n",
    "\n",
    "def is_repeated(cnt):\n",
    "    for k,v in cnt.most_common(1):\n",
    "        freq = v/total_words(cnt)\n",
    "        # print 'freq=',freq\n",
    "        if freq > 0.5:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def make_feature_vector(critique, labels):\n",
    "    \" construct feature vector\" \n",
    "    feature_vector = []\n",
    "    for i in range(len(critique)):\n",
    "        s = critique[i]\n",
    "        feature = []\n",
    "        counter_obj = words_counter_object(s)\n",
    "\n",
    "        feature.append(number_of_chars(s))\n",
    "        feature.append(unique_chars(s))\n",
    "        feature.append(weighted_unique_chars(s))\n",
    "        feature.append(total_words(counter_obj))\n",
    "        feature.append(is_repeated(counter_obj))\n",
    "\n",
    "        feature.append(labels[i])\n",
    "        feature_vector.append(feature)\n",
    "\n",
    "    return feature_vector\n",
    "\n",
    "def read_data():\n",
    "    ''' read and make a list of critiques'''\n",
    "    df = pd.read_csv('data/Evaluations-Binary.csv')\n",
    "    critiques,labels = df['Review'].tolist(),df['Useful'].tolist()\n",
    "    return critiques,labels\n",
    "#     data = []\n",
    "#     for index,rows in df.iterrows():\n",
    "#         a = (rows['Review'],rows['Useful'])\n",
    "#         data.append(a)\n",
    "#     f = open('/home/rohan/projects/teacher-review-sentiment-analysis/data/bad.txt', 'r')\n",
    "#     bad = f.read().split('|')\n",
    "#     f.close()\n",
    "\n",
    "#     f = open('/home/rohan/projects/teacher-review-sentiment-analysis/data/good.txt', 'r')\n",
    "#     good = f.read().split('|')\n",
    "#     f.close()\n",
    "\n",
    "#     return bad+good, [0]*len(bad) + [1]*len(good)\n",
    "\n",
    "def make_np_array_XY(xy):\n",
    "    print 'make_np_array_XY()'\n",
    "    a = np.array(xy)\n",
    "    x = a[:,0:-1]\n",
    "    y = a[:,-1]\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make_np_array_XY()\n",
      "make_np_array_XY()\n",
      "type(svc)= <class 'sklearn.svm.classes.SVC'>\n",
      "svc= SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Y_test:\n",
      "[ 1.  0.  1.  1.  1.  0.  1.  1.  0.  0.  1.  0.  1.  0.  1.  0.  1.  1.\n",
      "  1.  1.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.  1.  0.  1.  1.  1.  0.\n",
      "  1.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.  1.  1.  1.  0.  0.\n",
      "  1.  1.  1.  0.  0.  1.]\n",
      "Y_predict:\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.]\n",
      "Got 54 out of 78\n",
      "f1 macro = 0.41\n",
      "f1 micro = 0.69\n",
      "f1 weighted = 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "critiques, labels = read_data()\n",
    "features_and_labels= make_feature_vector(critiques, labels)\n",
    "number_of_features = len(features_and_labels[0]) - 1\n",
    "random.shuffle(features_and_labels)\n",
    "\n",
    "# make  train / test sets from the shuffled list\n",
    "cut = int(len(features_and_labels)/2)\n",
    "XY_train = features_and_labels[:cut]\n",
    "XY_test = features_and_labels[cut:]\n",
    "\n",
    "X_train, Y_train = make_np_array_XY(XY_train)\n",
    "\n",
    "X_test, Y_test = make_np_array_XY(XY_test)\n",
    "\n",
    "# train set\n",
    "C = 1.0  # SVM regularization parameter\n",
    "svc = svm.SVC(kernel='linear', C=C).fit(X_train, Y_train)\n",
    "print 'type(svc)=', type(svc)\n",
    "print 'svc=',svc\n",
    "\n",
    "print 'Y_test:\\n', Y_test\n",
    "\n",
    "Y_predict = svc.predict(X_test)\n",
    "print 'Y_predict:\\n', Y_predict\n",
    "\n",
    "# score\n",
    "test_size = len(Y_test)\n",
    "score = 0\n",
    "for i in range(test_size):\n",
    "    if Y_predict[i] == Y_test[i]:\n",
    "        score += 1\n",
    "\n",
    "print 'Got %s out of %s' %(score, test_size)\n",
    "\n",
    "# f1 score\n",
    "f1 = f1_score(Y_test, Y_predict, average='macro')  \n",
    "print 'f1 macro = %.2f' %(f1)\n",
    "f1 = f1_score(Y_test, Y_predict, average='micro')  \n",
    "print 'f1 micro = %.2f' %(f1)\n",
    "f1 = f1_score(Y_test, Y_predict, average='weighted')  \n",
    "print 'f1 weighted = %.2f' %(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
